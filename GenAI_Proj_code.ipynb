{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwrK--4Iifg9",
        "outputId": "da5cc4f4-9e0b-4332-d83f-66e57cbf2045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit transformers torch torchvision pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0RrlJe6jzRC"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHcQhwCxjMon",
        "outputId": "d1da65c9-8838-415f-e8f4-b542a0f89373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GenAI_Project\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/GenAI_Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0XtSLeXjvY_",
        "outputId": "56f94a12-81d1-4f70-f015-cc028aa06afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load BLIP (image captioning model)\n",
        "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Load FLAN-T5 (text generation model)\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "def generate_caption(image: Image.Image) -> str:\n",
        "    inputs = blip_processor(image, return_tensors=\"pt\")\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "def classify_scene(caption: str) -> str:\n",
        "    caption = caption.lower()\n",
        "    if any(word in caption for word in [\"mountain\", \"river\", \"forest\", \"sunset\", \"beach\", \"sky\", \"nature\", \"landscape\", \"tree\"]):\n",
        "        return \"landscape\"\n",
        "    elif any(word in caption for word in [\"person\", \"people\", \"man\", \"woman\", \"child\", \"face\", \"crowd\"]):\n",
        "        return \"people\"\n",
        "    elif any(word in caption for word in [\"building\", \"street\", \"city\", \"village\", \"car\", \"bridge\"]):\n",
        "        return \"urban or rural\"\n",
        "    elif any(word in caption for word in [\"abstract\", \"pattern\", \"shape\", \"color\", \"texture\"]):\n",
        "        return \"abstract or artistic\"\n",
        "    else:\n",
        "        return \"general scene\"\n",
        "\n",
        "def style_prompt(caption: str, style: str, tone: str, length: str) -> str:\n",
        "    tone_map = {\n",
        "        \"Neutral\": \"\",\n",
        "        \"Dark\": \" with a dark or mysterious tone\",\n",
        "        \"Dreamy\": \" in a dreamy, surreal style\",\n",
        "        \"Humorous\": \" with a humorous, witty touch\",\n",
        "        \"Sci-Fi\": \" imagining a futuristic, sci-fi world\",\n",
        "        \"Romantic\": \" with a romantic and emotional feel\",\n",
        "    }\n",
        "\n",
        "    length_map = {\n",
        "        \"Short\": \"Keep it brief.\",\n",
        "        \"Medium\": \"Keep it moderately detailed.\",\n",
        "        \"Long\": \"Make it detailed and elaborate.\",\n",
        "    }\n",
        "\n",
        "    scene_type = classify_scene(caption)\n",
        "    scene_context = f\"This is likely a {scene_type}. \"\n",
        "\n",
        "    caption_clean = caption.strip().lower().capitalize()\n",
        "\n",
        "    if style == \"Poetic\":\n",
        "        prompt = f\"{scene_context}Write a poem about the scene: '{caption_clean}'{tone_map[tone]}. {length_map[length]}\"\n",
        "    elif style == \"Fictional\":\n",
        "        prompt = f\"{scene_context}Write a fictional story inspired by: '{caption_clean}'{tone_map[tone]}. {length_map[length]}\"\n",
        "    elif style == \"Interpretive\":\n",
        "        prompt = f\"{scene_context}Interpret this image in a philosophical way based on: '{caption_clean}'{tone_map[tone]}. {length_map[length]}\"\n",
        "    else:\n",
        "        prompt = f\"{scene_context}Describe the image creatively: '{caption_clean}'{tone_map[tone]}. {length_map[length]}\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def generate_stylized_text(prompt: str) -> str:\n",
        "    input_ids = t5_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    outputs = t5_model.generate(input_ids, max_length=150, do_sample=True, top_k=50, top_p=0.95)\n",
        "    result = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GPiSoASj2tC",
        "outputId": "913d4891-c68e-483f-e8a7-6317dc093a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from utils import generate_caption, style_prompt, generate_stylized_text\n",
        "\n",
        "st.set_page_config(page_title=\"ArtPrompt\", layout=\"centered\")\n",
        "st.title(\"🎨 ArtPrompt\")\n",
        "st.subheader(\"Turn images into stories, poems, or interpretations using AI!\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    style = st.selectbox(\"Choose a base style\", [\"Standard\", \"Poetic\", \"Interpretive\", \"Fictional\"])\n",
        "    tone = st.selectbox(\"Pick a tone or mood\", [\"Neutral\", \"Dark\", \"Dreamy\", \"Humorous\", \"Sci-Fi\", \"Romantic\"])\n",
        "    length = st.selectbox(\"Select output length\", [\"Short\", \"Medium\", \"Long\"])\n",
        "\n",
        "\n",
        "    if st.button(\"Generate Description\"):\n",
        "        with st.spinner(\"Generating...\"):\n",
        "            caption = generate_caption(image)\n",
        "            prompt = style_prompt(caption, style, tone, length)\n",
        "            output = generate_stylized_text(prompt)\n",
        "\n",
        "        st.markdown(\"### 🧾 Generated Description\")\n",
        "        st.write(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG-_9UBlj7Ua"
      },
      "outputs": [],
      "source": [
        "from pyngrok import conf, ngrok\n",
        "\n",
        "conf.get_default().auth_token = \"YOUR NGROK API KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MKRr4vD6yJS"
      },
      "outputs": [],
      "source": [
        "!pkill streamlit\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuQK1d7flKP_"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/drive/MyDrive/GenAI_Project/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyM74vMkkCRN",
        "outputId": "3c2cebfe-207b-4e40-9bd2-ad6106ab95a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "App is live at 👉 NgrokTunnel: \"https://493c-34-125-96-155.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(\"8501\", \"http\")\n",
        "print(f\"App is live at 👉 {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB0WncIx40iR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
